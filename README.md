# ğŸšˆ Gesture-Controlled Drone Simulator

A real-time Unity-powered drone simulator controlled via hand gestures using Python, MediaPipe, and OpenCV.

---

## ğŸ“Œ Project Overview

This project bridges **Python-based gesture recognition** with a **Unity-based 3D drone simulation**. Users can control a drone using **hand gestures** detected through a webcam, powered by **MediaPipe's hand tracking**.

Python handles gesture tracking and sends data to Unity using **sockets**. Unity reads this data in real-time to control the drone's movement in a simulated environment.

---

## âœ¨ Features

* ğŸ® Real-time drone control using hand gestures
* ğŸ–ï¸ Hand tracking using MediaPipe
* ğŸ”„ Seamless integration between Python and Unity via TCP sockets
* ğŸ§  Support for both gesture and keyboard control
* ğŸ•¹ï¸ Smooth, physics-based drone movement
* ğŸ” Auto-launch of Python script from Unity using `.bat` file

---

## ğŸ”§ Technologies Used

### ğŸ Python

* **Python 3.9.13** (only this version recommended for MediaPipe compatibility)
* [MediaPipe](https://google.github.io/mediapipe/) (v0.10.21)
* [OpenCV](https://opencv.org/) (`cv2`)
* `socket`, `math`, `threading`, `json` (standard libraries)

### ğŸ® Unity

* **Unity Editor 2022.3 LTS** (recommended)
* Unity C# scripting for movement and socket communication
* `.bat` file to auto-run Python gesture script

---

## ğŸ–¥ï¸ System Requirements

* **Operating System**: Windows 10/11
* **Python**: 3.9.13
* **Unity**: Unity Hub + Unity Editor 2022.3 LTS
* **Webcam**: Functional webcam required
* **Git** (for cloning project)

---

## âš™ï¸ Installation

### 1. Clone the Repository

```bash
      git clone https://github.com/your-username/Gesture-control-drone-simulator.git
      cd Gesture-control-drone-simulator
```

### 2. Set Up Python Environment

```bash
      # Create virtual environment
      python -m venv mediapipe_env

      # Activate it (Windows)
      mediapipe_env\Scripts\activate

      # Install dependencies
      pip install -r requirements.txt
```

`requirements.txt` should contain:

```txt
      mediapipe==0.10.21
      opencv-python
```

### 3. Open Unity Project

* Open **Unity Hub** â†’ Click **"Open"**
* Navigate to this cloned folder
* Wait for Unity to index and compile the project

## â–¶ï¸ How to Run the Project

1. Press **Play** in Unity Editor to start the simulation
2. Unity executes a `.bat` file that starts `main.py` (gesture tracker)

### ğŸ”„ Python Side

* Accesses your webcam
* Detects hand landmarks via MediaPipe
* Sends real-time gesture data to Unity over socket

### ğŸ® Unity Side

* Receives this data
* Updates the drone's motion accordingly

## ğŸ® Controls

| Action            | Gesture / Input             |
| ----------------- | --------------------------- |
| Move Forward      | Right Index Finger Extended |
| Move Backward     | Left Index Finger Extended  |
| Turn Left / Right | Move Left Thumb (X-axis)    |
| Ascend / Descend  | Move Right Thumb (Y-axis)   |
| Roll              | Keyboard A / D              |
| Keyboard Movement | W / S / Space / Left Ctrl   |

## ğŸ§  How It Works

### ğŸ¯ Gesture Detection

* MediaPipe tracks both hands with 21 landmarks
* Uses thumb and index finger position for gesture interpretation

### ğŸŒ Data Communication

* Python acts as a TCP server (`localhost:5000`)
* Unity connects to this server and reads gesture JSON frames
* Unity C# parses input and applies movement to drone using physics

### âš™ï¸ Automation

* `.bat` file is used to start Python script automatically when Unity scene starts

## ğŸ› ï¸ Troubleshooting & FAQ

### â“ Python script doesn't start

* Ensure `.bat` file path is correct and points to `main.py`
* Test `main.py` by running manually:

```bash
    python main.py
```

### â“ Unity fails to connect to Python

* Make sure `main.py` is running
* Check if port `5000` is already in use
* Avoid running multiple instances of Unity or Python together

### â“ Gesture input not detected

* Ensure webcam is accessible
* Check lighting conditions
* Verify correct Python version (`3.9.13`)

---

## ğŸ“‚ Project Structure

```bash
  Gesture-control-drone-simulator/
  â”œâ”€â”€ Assets/
  â”‚   â”œâ”€â”€ External/              # main.py and .bat file
  â”‚   â”œâ”€â”€ Scripts/               # Unity C# scripts
  â”‚   â””â”€â”€ Scenes/
  â”œâ”€â”€ mediapipe_env/             # Python venv
  â”œâ”€â”€ requirements.txt
  â”œâ”€â”€ README.md
  â””â”€â”€ .gitignore
```

## ğŸ“¸ Screenshots / Demo

  <img width="480" height="300" alt="Drone Simulator with Hand Control" src="https://github.com/user-attachments/assets/97209a75-d436-4752-b4dc-1b2e5720a9e7" />
  <img width="480" height="300" alt="Hand Gesture Tracking" src="https://github.com/user-attachments/assets/d5f61839-3dbf-4841-8cbd-6666472566a7" />

**Assets used in the Unity project:**

* [Japanese Otaku City](https://assetstore.unity.com/packages/3d/environments/urban/japanese-otaku-city-20359) â€” for the city environment
* [Simple Drone](https://assetstore.unity.com/packages/3d/vehicles/air/simple-drone-190684) â€” for the drone model

## ğŸ¤ Contributing

Contributions are welcome! You can:

* Submit bug reports
* Improve gesture detection accuracy
* Enhance UI/UX in Unity

---

## ğŸ“¬ Contact

**Dhanesh Vaghasiya**
GitHub: [@dhanesh-vaghasiya](https://github.com/dhanesh-vaghasiya)
Email: [dhaneshvaghasiya999@gmail.com](mailto:dhaneshvaghasiya999@gmail.com)
