# ğŸ›¸ Gesture-Controlled Drone Simulator

A real-time Unity-powered drone simulator controlled via hand gestures using Python, MediaPipe, and OpenCV.

---

## ğŸ“Œ Project Overview

This project bridges **Python-based gesture recognition** with a **Unity-based 3D drone simulation**. Users can control a drone using **hand gestures** detected through a webcam, powered by **MediaPipe's hand tracking**.

Python handles gesture tracking and sends data to Unity using **sockets**. Unity reads this data in real-time to control the drone's movement in a simulated environment.

---

## âœ¨ Features

- ğŸ® Real-time drone control using hand gestures  
- ğŸ–ï¸ Hand tracking using MediaPipe  
- ğŸ”„ Seamless integration between Python and Unity via TCP sockets  
- ğŸ§  Support for both gesture and keyboard control  
- ğŸ•¹ï¸ Smooth, physics-based drone movement  
- ğŸ” Auto-launch of Python script from Unity using `.bat` file  

---

## ğŸ”§ Technologies Used

### ğŸ Python

- **Python 3.9.13** (only this version recommended for MediaPipe compatibility)
- [MediaPipe](https://google.github.io/mediapipe/) (v0.10.21)
- [OpenCV](https://opencv.org/) (`cv2`)
- `socket`, `math`, `threading`, `json` (standard libraries)

### ğŸ® Unity

- **Unity Editor 2022.3 LTS** (recommended)
- Unity C# scripting for movement and socket communication
- `.bat` file to auto-run Python gesture script

---

## ğŸ–¥ï¸ System Requirements

- **Operating System**: Windows 10/11
- **Python**: 3.9.13
- **Unity**: Unity Hub + Unity Editor 2022.3 LTS
- **Webcam**: Functional webcam required
- **Git** (for cloning project)

---

## âš™ï¸ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/Gesture-control-drone-simulator.git
cd Gesture-control-drone-simulator
2. Set Up Python Environment
bash
Copy
Edit
# Create virtual environment
python -m venv mediapipe_env

# Activate it (Windows)
mediapipe_env\Scripts\activate

# Install dependencies
pip install -r requirements.txt
requirements.txt should contain:
makefile
Copy
Edit
mediapipe==0.10.21
opencv-python
3. Open Unity Project
Open Unity Hub â†’ "Open"

Navigate to this cloned folder

Wait for Unity to index and compile the project

â–¶ï¸ How to Run the Project
Press Play in Unity Editor to start the simulation.

Unity executes a .bat file that starts main.py (gesture tracker).

Python:

Accesses your webcam

Detects hand landmarks via MediaPipe

Sends real-time gesture data to Unity over socket

Unity receives this data and updates the drone's motion accordingly.

ğŸ® Controls
Action	Gesture / Input
Move Forward	Right Index Finger Extended
Move Backward	Left Index Finger Extended
Turn Left / Right	Move Left Thumb (X-axis)
Ascend / Descend	Move Right Thumb (Y-axis)
Roll	Keyboard A/D
Keyboard Movement	W/S/Space/Left Ctrl

ğŸ§  How It Works
Gesture Detection:

MediaPipe tracks both hands with 21 landmarks

Uses thumb and index finger position for gesture interpretation

Data Communication:

Python acts as a TCP server (localhost:5000)

Unity connects to this server and reads gesture JSON frames

Unity C# parses input and applies movement to drone using physics

Automation:

.bat file is used to start Python script automatically when Unity scene starts

ğŸ› ï¸ Troubleshooting & FAQ
â“ Python script doesn't start
Ensure .bat file path is correct and points to main.py

Test main.py by running manually:
python main.py

â“ Unity fails to connect to Python
Make sure main.py is running

Check if port 5000 is already in use

Avoid running multiple instances of Unity/Python together

â“ Gesture input not detected
Ensure webcam is accessible

Check lighting conditions

Verify correct Python version (3.9.13)

ğŸ“‚ Project Structure
bash
Copy
Edit
Gesture-control-drone-simulator/
â”œâ”€â”€ Assets/
â”‚   â”œâ”€â”€ External/              # main.py and .bat file
â”‚   â”œâ”€â”€ Scripts/               # Unity C# scripts
â”‚   â””â”€â”€ Scenes/
â”œâ”€â”€ mediapipe_env/             # Python venv
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

ğŸ“¸ Screenshots / Demo


ğŸ“„ License
This project is open-source and available under the MIT License.

ğŸ¤ Contributing
Contributions are welcome! You can:

Submit bug reports

Improve gesture detection accuracy

Enhance UI/UX in Unity

ğŸ“¬ Contact
For any questions or suggestions:

Dhanesh Vaghasiya
GitHub: @dhanesh-vaghasiya
Email: [dhaneshvaghasiya999@gmail.com]
